{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import GPTModel, generate_text_simple\n",
    "import tiktoken\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,                                        \n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12, \n",
    "    \"drop_rate\": 0.1,                                             \n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves youEvery\n"
     ]
    }
   ],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze().tolist()\n",
    "    decoded = tokenizer.decode(flat)\n",
    "    return decoded \n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"files/the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens:  5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters: \", total_characters)\n",
    "print(\"Tokens: \", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import create_dataloader_v1\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"], \n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    \n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device): \n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), \n",
    "        target_batch.flatten(),\n",
    "    )\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0: \n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None: \n",
    "        num_batches = len(data_loader)\n",
    "    else: \n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches: \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else: \n",
    "            break   \n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  10.98866695827908\n",
      "Test loss 10.96247673034668\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "    \n",
    "print(\"Training loss: \", train_loss)\n",
    "print(\"Test loss\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()                                                   #A\n",
    "    with torch.no_grad():                                          #B\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "    model.train()                                                  #C\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50, \n",
    "            context_size=context_size\n",
    "        )\n",
    "        decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "        print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                    eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []      #A\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    for epoch in range(num_epochs):                               #B\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()                                 #C\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()                                       #D\n",
    "            optimizer.step()                                      #E\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "            if global_step % eval_freq == 0:                    #F \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                        f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "        generate_and_print_sample(                                #G\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 10.064, Val loss 9.928\n",
      "Ep 1 (Step 000005): Train loss 7.734, Val loss 8.336\n",
      "Every effort moves you,\n",
      "Ep 2 (Step 000010): Train loss 6.357, Val loss 7.038\n",
      "Ep 2 (Step 000015): Train loss 5.995, Val loss 6.593\n",
      "Every effort moves you,\n",
      "Ep 3 (Step 000020): Train loss 16.089, Val loss 15.890\n",
      "Ep 3 (Step 000025): Train loss 5.265, Val loss 6.463\n",
      "Every effort moves you.\n",
      "Ep 4 (Step 000030): Train loss 5.261, Val loss 6.325\n",
      "Ep 4 (Step 000035): Train loss 5.021, Val loss 6.247\n",
      "Every effort moves you,\n",
      "Ep 5 (Step 000040): Train loss 3.802, Val loss 6.257\n",
      "Every effort moves you know\n",
      "Ep 6 (Step 000045): Train loss 3.969, Val loss 6.210\n",
      "Ep 6 (Step 000050): Train loss 3.041, Val loss 6.181\n",
      "Every effort moves you know\n",
      "Ep 7 (Step 000055): Train loss 2.375, Val loss 6.200\n",
      "Ep 7 (Step 000060): Train loss 1.944, Val loss 6.168\n",
      "Every effort moves you know\n",
      "Ep 8 (Step 000065): Train loss 2.166, Val loss 6.182\n",
      "Ep 8 (Step 000070): Train loss 1.146, Val loss 6.165\n",
      "Every effort moves you?\"\n",
      "Ep 9 (Step 000075): Train loss 1.168, Val loss 6.282\n",
      "Ep 9 (Step 000080): Train loss 0.779, Val loss 6.305\n",
      "Every effort moves you?\"\n",
      "Ep 10 (Step 000085): Train loss 0.576, Val loss 6.392\n",
      "Every effort moves you?\"\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) #A\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=1,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax2 = ax1.twiny()                                             \n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)                  \n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "                temperature=1.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):                               #A\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        if top_k is not None:                                     #B\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "    \n",
    "        if temperature > 0.0:                                         #C\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:                                                     #D\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "        if idx_next == eos_id:                                    #E\n",
    "            break\n",
    "    idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x20cf726cad0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
